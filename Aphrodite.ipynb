{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Aphrodite.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN+U0YTnClvib4lzCOW+t5b"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"AeRt-iUe39dh","colab_type":"text"},"source":["**(SRGAN) with pytorch**\n","\n"," we build a model that can realistically increase image resolution. \n","\n","\n","Using *PyTorch 1.4* in *Python 3.6*."]},{"cell_type":"code","metadata":{"id":"DSbBGJ8RN0ny","colab_type":"code","outputId":"60712a43-374a-4768-f51f-842377d6aaf8","executionInfo":{"status":"ok","timestamp":1585747429134,"user_tz":-120,"elapsed":1713,"user":{"displayName":"Mahmoud F.Toraih","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTfRdgDp1fxbBcF7XCK-xlTTdTT7m-y-cNAxSplg=s64","userId":"01391135744838768738"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["#this code to connect or mount your Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eurcVzLbQrll","colab_type":"code","colab":{}},"source":["import sys\n","\n","sys.path.append('/content/drive/My Drive/Aphrodite-SRGAN')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"miq1QHMN49cF","colab_type":"text"},"source":["**our checkpoints are available**    [SRGAN (TAR)]( https://drive.google.com/open?id=1ePooVQcEbIjEZfE2ED1dmtCVj-xUbg1c )\n","you can download it .\n","we train about 3000 epoch from [DIV2K](https://data.vision.ee.ethz.ch/cvl/DIV2K/) dataset .\n","if you want to train another dataset this [link](https://drive.google.com/open?id=1qEEX29LyVP2NjNxYw2WR-KcehjdSCjEM) for our project you can `run` file : train-srgan.py"]},{"cell_type":"code","metadata":{"id":"_IZ1q2p1HOo0","colab_type":"code","colab":{}},"source":["\n","\n","   \n","    \n","#----------------------------------------------------------\n","from utils import *\n","from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n","from datasets import SRDataset\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","from torch import argmax\n","from google.colab import files\n","from PIL import Image, ImageDraw, ImageFont\n","from PIL import Image, ImageEnhance  , ImageFilter\n","from google.colab import files\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","def afro(url):\n","  \n","# Data\n","\n","  test_data_names = [\"DIV2k\"]\n","\n","# Model checkpoints\n","  srgan_checkpoint = \"/content/drive/My Drive/SRGAN (TAR)/checkpoint_srgan.pth.tar\"\n","  \n","# Load model,  the   the SRGAN\n","\n","  srgan_generator = torch.load(srgan_checkpoint)['generator'].to(device)\n","  srgan_generator.eval()\n","  model = srgan_generator\n","\n","# Evaluate\n","  for test_data_name in test_data_names:\n","  \n","\n","    # Custom dataloader\n","     test_dataset = SRDataset(url= url,\n","                             split='test',\n","                             crop_size=0,\n","                             scaling_factor=4,\n","                             lr_img_type='imagenet-norm',\n","                             hr_img_type='[-1, 1]',\n","                             test_data_name=test_data_name)\n","     test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4,\n","                                              pin_memory=True)\n","\n","    \n","\n","    # Prohibit gradient computation explicitly because I had some problems with memory\n","     with torch.no_grad():\n","        # Batches\n","         for i, (lr_imgs, hr_imgs) in enumerate(test_loader):\n","            # Move to default device\n","            lr_imgs = lr_imgs.to(device)  # (batch_size (1), 3, w / 4, h / 4), imagenet-normed\n","            hr_imgs = hr_imgs.to(device)  # (batch_size (1), 3, w, h), in [-1, 1]\n","            # Forward prop.\n","            sr_imgs = model(lr_imgs)# (1, 3, w, h), in [-1, 1]\n","\n","           \n","           \n","            sr_img_srgan = sr_imgs.squeeze(0).cpu().detach()\n","            sr_img_srgan = convert_image(sr_img_srgan, source='[-1, 1]', target='pil')\n","           \n","            mr_img = sr_img_srgan.resize((int(sr_img_srgan.width *1), int(sr_img_srgan.height *1)))\n","            smoothenedImage = mr_img.filter(ImageFilter.SMOOTH)\n","\n","            moreSmoothenedImage = smoothenedImage.filter(ImageFilter.SMOOTH_MORE)\n","            im3 = ImageEnhance.Sharpness(moreSmoothenedImage) \n","            \n","            print(mr_img.width)\n","            # showing resultant image \n","            \n","            plt.imshow(im3.enhance(-5.0))\n","           # plt.imshow(sr_img_srgan)\n","            # Calculate PSNR and SSIM\n","            sr_imgs_y = convert_image(sr_imgs, source='[-1, 1]', target='y-channel').squeeze(\n","                0)  # (w, h), in y-channel\n","            hr_imgs_y = convert_image(hr_imgs, source='[-1, 1]', target='y-channel').squeeze(0)  # (w, h), in y-channel\n","            \n","    \n","\n","\n","  print(\"\\n\")\n","#------------------------------------------------------------------------\n","\n","afro('/content/drive/My Drive/Aphrodite-Project/images/low1.png')\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cundIcg0_Svr","colab_type":"text"},"source":["you can test the code : just change the *url* in `afro(url)`"]}]}